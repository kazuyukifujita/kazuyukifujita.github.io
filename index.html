<!DOCTYPE html>
<html lang="en">
	<head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-122737981-2"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-122737981-2');
        </script>

		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
		<meta name="description" content="">
		<meta name="author" content="">
		<link rel="icon" type="image/png" href="images/logo.png">
		<title>Kazuyuki FUJITA</title>
		<!-- Bootstrap core CSS -->
		<link href="css/bootstrap.min.css" rel="stylesheet">
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Lato:400,700|Noto+Sans+JP:400,700" rel="stylesheet">
		<!-- Custom styles for this template -->
		<link href="css/style.css" rel="stylesheet">
	</head>
	<body id="page-top">
		<!-- Navigation -->
		<nav class="navbar navbar-default">
			<div class="container">
				<!-- Brand and toggle get grouped for better mobile display -->
				<div class="navbar-header page-scroll">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					</button>
					<h1><a class="navbar-brand page-scroll" href="#page-top"><img src="images/logo.png" height="36" alt="Kazuyuki FUJITA"></a>Kazuyuki FUJITA</h1>

				</div>
				<!-- Collect the nav links, forms, and other content for toggling -->
				<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
					<ul class="nav navbar-nav navbar-right">
						<li class="hidden">
							<a href="#page-top"></a>
						</li>
						<li>
							<a class="page-scroll" href="#about">About me</a>
						</li>
						<li>
							<a class="page-scroll" href="#research">Reseach</a>
						</li>
						<li>
							<a class="page-scroll" href="#publications">Publications</a>
						</li>
					</ul>
				</div>
				<!-- /.navbar-collapse -->
			</div>
			<!-- /.container-fluid -->
		</nav>

		<section id="about">
			<div class="container">
			<div class="row">
				<div class="col-lg-12 text-center">
					<div class="section-title">
                    <h2>About me</h2>
					</div>
                    <figure class="portofolio"><img src="images/fujita_photo.jpg" alt="Kazuyuki FUJITA"></figure>
                    <p class="text-left">
                    Kazuyuki FUJITA is an Assistant Professor in <a href="https://www.icd.riec.tohoku.ac.jp/index.html">ICD Lab.</a>, <a href="http://www.riec.tohoku.ac.jp">Research Institute of Electrical Communication</a> at <a href="https://www.tohoku.ac.jp">Tohoku University</a>.
                    He received his Ph.D. in Information Science and Technology from <a href="https://www.osaka-u.ac.jp/">Osaka University</a> in 2013. He worked for <a href="https://www.itoki.jp/">ITOKI</a>, an office space design company, and was engaged in research and development on future offices for 2013-2018. His research interest includes Human-Computer Interaction and Virtual Reality.
                    </p>
										<p class="text-left-clear">
											Contact: k-fujita [at] riec.tohoku.ac.jp
										</p>
										<p class="text-left-clear">
											<a class="icd" href="http://www.icd.riec.tohoku.ac.jp/index.html">Information Content Design Lab (ICD Lab)</a>
										</p>
										<p class="text-left-clear">
											<a class="scholar" href="https://scholar.google.co.jp/citations?user=GEglw3kAAAAJ">Google Scholar page</a>
										</p>
										<p class="text-left-clear">
											<a class="researchmap" href="https://researchmap.jp/kazuyukifujita/">researchmap</a> (in Japanese)
										</p>
										<p class="text-left-clear">
											<a class="twitter" href="https://twitter.com/kekure">Twitter</a>
										</p>

				</div>
			</div>

			</div><!-- container -->
		</section>

		<section id="research">
			<div class="container">
				<div class="row">
					<div class="col-lg-12 text-center">
						<div class="section-title">
							<h2>Research</h2>
						</div>
          </div>
				</div>

				<div class="row">
						<div class="container">
								<h3>
										Adaptive Workspace
								</h3>
						</div>
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/redirectedjump.png" class="img-responsive" alt="Redirected Jumping">
								</div>
								<div class="team-text">
									<h3>Redirected Jumping</h3>
									<div class="team-position"><span class="conference">IEEE VR 2019</span></div>
									<div class="team-position"><a href="https://www.icd.riec.tohoku.ac.jp/project/vr/project_redirect_jump_e.html">project page</a> / paper / <a href="https://youtu.be/kR9YI4kdgJI">video</a></div>
									<p>
										We explore Redirected Jumping, a novel redirection technique which enables us to purposefully manipulate the mapping of the user’s physical jumping movements (e.g., distance and direction) to movement in the virtual space, allowing richer and more active physical VR experiences within a limited tracking area.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/ai_meeting.jpg" class="img-responsive" alt="AI-Supported Meeting Space">
								</div>
								<div class="team-text">
									<h3>AI-Supported Meeting Space</h3>
									<div class="team-position"><span class="conference">JSAI 2017 (Domestic)</displacements></div>
									<div class="team-position"><a href="https://doi.org/10.11517/pjsai.JSAI2017.0_2P14">paper</a></div>
									<p>
										AI-Supported Meeting Space itself behaves as “another participant” to make the meeting more productive. The system periodically provides the participants with some information related to their discussion topics on the surface of the table and walls.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/ambientsuite.jpg" class="img-responsive" alt="Ambient Suite">
								</div>
								<div class="team-text">
									<h3>Ambient Suite</h3>
									<div class="team-position"><span class="conference">ACE 2011</span></div>
									<div class="team-position"><a href="https://doi.org/10.1145/2071423.2071454">paper</a></div>
									<p>
                                    Ambient Suite enhances communication among multiple participants. In Ambient Suite itself works as both sensors to estimate the conversation states of participants from nonverbal cues and displays to present information to stimulate conversation.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
					</div>
					<div class="row">
						<div class="container">
	                        <h3>Graphical User Interface</h3>
            </div>

						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/dflip.jpg" class="img-responsive" alt="D-FLIP">
								</div>
								<div class="team-text">
									<h3>D-FLIP</h3>
									<div class="team-position"><span class="conference">ISS 2018 demo</span></div>
									<div class="team-position"><a href="https://www.icd.riec.tohoku.ac.jp/project/project_D-Flip/project_D-Flip_e.html">project page</a> / <a href="https://doi.org/10.1145/3279778.3279923">paper</a> / <a href="https://youtu.be/dm1i0dFCiyI">video</a></div>
                                    <p>
										D-FLIP dynamically and flexibly visualizes digital photos and their metadata. We design various dynamic photo visualizations with up to four-dimensional meta-information, allowing users to dynamically and effectively manage photos by selecting meta-information of user's current needs and interest.
									</p>
								</div>
							</div>
						</div>
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/elastic2.png" class="img-responsive" alt="elastic scroll and zoom">
								</div>
								<div class="team-text">
									<h3>Elastic Scroll and Zoom</h3>
									<div class="team-position"><span class="conference">UIST 2012 demo</span></div>
									<div class="team-position"><a href="https://doi.org/10.1145/2380296.2380307">paper</a> / <a href="https://youtu.be/bW6rc7RDUwY">video</a></div>
									<p>
										Elastic Scroll and Zoom is a viewport control method using metaphor of flexible materials. When a user scrolls or zooms the content to acquire a new area, originally displayed area remains in the viewport with distortion, which helps users decide next operation.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/anchorednavi.png" class="img-responsive" alt="Anchored Navigation">
								</div>
								<div class="team-text">
									<h3>Anchored Navigation</h3>
									<div class="team-position"><span class="conference">GI 2010</span></div>
									<div class="team-position"><a href="https://dl.acm.org/citation.cfm?id=1839255">paper</a> / <a href="https://youtu.be/gLizKRp_-TU">video</a></div>
									<p>
										Anchored Navigation is a novel map navigation technique which allows users to manipulate a viewport without mode-switching among pan, zoom, and tilt while maintaining a sense of distance and direction by coupling users' panning displacements with zooming and panning so that the anchor point (determined by users) always remains in the viewport.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
					</div>
					<div class="row">
						<div class="container">
                <h3>
                    Haptic Interfaces
                </h3>
            </div>

						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/paranga.png" class="img-responsive" alt="Paranga">
								</div>
								<div class="team-text">
									<h3>Paranga</h3>
									<div class="team-position"><span class="conference">SIGGRAPH Asia 2011 E-Tech</span> <span class="conference">ACE 2012</span></div>
									<div class="team-position"><a href="https://doi.org/10.1007/978-3-642-34292-9_2">paper</a> / <a href="https://youtu.be/NqN9Y0zBEKk">video</a></div>

									<p>
										Paranga is a book-shaped device that brings e-books into physical features like paper-like texture and page-flipping sensation. Paranga detects how quickly a user is turning pages and provides the tactile feedback of turning pages on his/her thumb by employing a rotatable roller mechanism with pieces of real paper.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/fusa2.jpg" class="img-responsive" alt="FuSA2 Touch Display">
								</div>
								<div class="team-text">
									<h3>FuSA<sup>2</sup> Touch display</h3>
									<div class="team-position"><span class="conference">SIGGRAPH 2010 E-Tech</span> <span class="conference">ITS 2011</span></div>
									<div class="team-position"><a href="https://doi.org/10.1145/2076354.2076361">paper</a> / <a href="https://youtu.be/-MD-fOYe3AI">video</a></div>
									<p>
										FuSA2 Touch Display is a furry and scalable multi-touch display which affords various interactions such as stroking or clawing. The system utilizing the feature of plastic fiber optics realizes a furry-type texture and a simple configuration that integrates the input and output.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
						<!-- team member item -->
						<div class="col-md-4">
							<div class="team-item">
								<div class="team-image">
									<img src="images/research/funbrella.jpg" class="img-responsive" alt="Funbrella">
								</div>
								<div class="team-text">
									<h3>Funbrella</h3>
									<div class="team-position"><span class="conference">SIGGRAPH 2009 E-Tech</span> <span class="conference">ACE 2009</span></div>
									<div class="team-position"><a href="https://doi.org/10.1145/1690388.1690400">paper</a> / <a href="https://youtu.be/F1JrbdRH_yk">video</a></div>
									<p>
										Funbrella is an umbrella-like device that entertains people by reproducing various kinds of vibration perceived through an umbrella's handle while raining. We implemented a vibration-giving mechanism with an extremely simple structure based on a microphone / speaker so that the device can record the vibrations and plays them.
									</p>
								</div>
							</div>
						</div>
						<!-- end team member item -->
					</div>
			</div>
		</section>

		<section id="publications" class="mz-module">
			<div class="container light-bg">
				<div class="row">
					<div class="col-lg-12 text-center">
						<div class="section-title">
							<h2>Publications</h2>
						</div>
					</div>
				</div>
				<div class="row">
					<div class="text-left">
						<div class="mz-about-container">
<ul class="category">
<li>Journal Papers (Domestic / International)</li>
</ul>
<ol>
<li>伊藤雄一，藤田和之，城所宏行．パランガ：触覚フィードバックを持つ電子パラパラ漫画，日本バーチャルリアリティ学会論文誌 Vol. 19, No. 4, pp. 477-486, 2014年12月．</li>
<li>遠藤隆介，伊藤雄一，中島康祐，藤田和之，岸野文郎．マルチタッチディスプレイを用いた複数人によるプランニングができるデジタルサイネージシステムの提案，情報処理学会論文誌，Vol. 55, No. 4, 1275-1286, 2014年4月．</li>
<li>中島康祐，伊藤雄一，林勇介，池田和章，藤田和之，尾上孝雄．Emoballoon：ソーシャルタッチインタラクションのための柔らかな風船型インタフェース，日本バーチャルリアリティ学会論文誌 Vol. 18, No. 3, pp. 255-265, 2013年9月．</li>
<li>Kazuyuki Fujita, Yuichi Itoh, and Hiroyuki Kidokoro. “Paranga: An electronic flipbook that reproduces riffling interaction.” International Journal of Creative Interfaces and Computer Graphics (IJCICG), Vol. 4, No. 1, pp. 21-34, Jun.2013.	</li>
<li>Yusuke Hayashi, Yuichi Itoh, Kazuki Takashima, Kazuyuki Fujita, Kosuke Naka- jima, and Takao Onoye. Cup-le: cup-shaped tool for subtly collecting Information during conversational experiment, In International Journal of Advanced Computer Science, Vol. 3, No. 1, pp. 44-50, Jan. 2013.</li>
<li>藤田和之，高嶋和毅，伊藤雄一，大崎博之，小野直亮，香川景一郎，津川翔，中島康祐，林勇介，岸野文郎．Ambient Suiteを用いたパーティ場面における部屋型会話支援システムの実装と評価，電子情報通信学会論文誌, Vol. J96-D, No. 1, 2013年1月．</li>
<li>Ryusuke Endo, Yuichi Itoh, Kosuke Nakajima, Kazuyuki Fujita, and Fumio Kishino. Digital Signage Supporting Collaborative Route Planning in Real Commercial Establishment. ICIC Express Letters, Vol. 6, No. 12, pp. 1-6, Dec. 2012.</li>
<li>中島康祐，伊藤雄一，築谷喬之，藤田和之，高嶋和毅，岸野文郎．FuSA2 Touch Display: 大画面毛状マルチタッチディスプレイ，情報処理学会論文誌, Vol. 53, No. 3, pp. 1069-1081, 2012年3月．</li>
<li>藤田和之，高嶋和毅，築谷喬之，朝日元生，伊藤雄一，北村喜文，岸野文郎．地図ナビゲーションにおけるパン操作とズーム/チルト連動を用いたビューポート制御手法の提案，電子情報通信学会論文誌, Vol. J93-D, No. 11, pp. 2454-2465, 2010年11月．</li>
<li>藤田和之，伊藤雄一，吉田愛，尾崎麻耶，菊川哲也，深澤遼，高嶋和毅，北村喜文，岸野文郎．アソブレラ：振動を記録・再生可能な傘型アンビエントインタフェース，日本バーチャルリアリティ学会論文誌, Vol. 15, No. 3, pp. 397-405, 2010年9月．</li>

</ol>
<ul>
<li class="category">Reviewed Conference Papers（Full Paper）</li>

</ul>
<ol>
<li>Daigo Hayashi, Kazuyuki Fujita, Kazuki Takashima, Robert W. Lindeman, Yoshifumi Kitamura. Redirected Jumping: Imperceptibly Manipulating Jump Motions in Virtual Reality, Proc. of 2019 IEEE Virtual Reality Conference, Mar. 2019. </li>
<li>Kosuke Nakajima, Yuichi Itoh, Yusuke Hayashi, Kazuaki Ikeda, Kazuyuki Fujita, and Takao Onoye. Emoballoon: a Balloon-shaped Interface Recognizing Social Touch Interactions. Proc. of 10th International Conference on Advances in Computer Entertainment Technology (ACE &#39;13), pp. 182-197, Nov. 2013.</li>
<li>Kazuyuki Fujita, Hiroyuki Kidokoro, Yuichi Itoh. Paranga: An Interactive Flipbook, Proc. of the International Conference on Advances in Computer Entertainment Technology (ACE &#39;12), pp. 17-30, 2012.</li>
<li>Ryusuke Endo, Yuichi Itoh, Kosuke Nakajima, Kazuyuki Fujita, Fumio Kishino. Planning-Capable Digital Signage System Using Multi-touch Display, Proc. of The 10th Asia Pacific Conference on Computer Human Interaction (APCHI &#39;12), Vol. 2, pp. 545-554, Aug. 2012.</li>
<li>Kazuyuki Fujita, Yuichi Itoh, Hiroyuki Ohsaki, Naoaki Ono, Keiichiro Kagawa, Kazuki Takashima, Sho Tsugawa, Kosuke Nakajima, Yusuke Hayashi, Fumio Kishino. Ambient Suite: Enhancing Communication among Multiple Participants, Proc. of the International Conference on Advances in Computer Entertainment Technology (ACE &#39;11), pp. 25:1-25:8, Nov. 2011.</li>
<li>Kosuke Nakajima, Yuichi Itoh, Takayuki Tsukitani, Kazuyuki Fujita, Kazuki Takashima, Yoshifumi Kitamura, Fumio Kishino. FuSA2 Touch Display: Furry and Scalable Multi-touch Display, Proc. of ACM International Conference on Interactive Tabletops and Surfaces 2011 (ITS &#39;11), pp. 35-44, Nov. 2011.</li>
<li>Kazuyuki Fujita, Kazuki Takashima, Takayuki Tsukitani, Yuichi Itoh, Yoshifumi Kitamura, Fumio Kishino. Anchored Navigation: Coupling Panning Operation with Zooming and Tilting Based on the Anchor Point on a Map, Proc. of the Graphics Interface 2010 (GI &#39;10), pp. 233-240, May. 2010.</li>
<li>Kazuyuki Fujita, Yuichi Itoh, Ai Yoshida, Maya Ozaki, Kikukawa Tetsuya, Ryo Fukazawa, Kazuki Takashima, Yoshifumi Kitamura, Fumio Kishino. Funbrella: Recording and Replaying Vibrations through an Umbrella Axis, Proc. of the International Conference on Advances in Computer Entertainment Technology (ACE &#39;09), pp. 66-71, Oct. 2009.</li>

</ol>
<ul>
<li class="category">Reviewed Conference Papers（Short Paper / Poster / Demo）</li>

</ul>
<ol>
<li>Yoshitaka Ishihara, Shori Ueda, Yuichi Itoh, Kazuyuki Fujita. PlanT: A Plant-based Ambient Display Visualizing Gradually Accumulated Information. Asian CHI Symposium: Emerging HCI Research Collection, May. 2019. <em>Best Demo/Poster Award</em>.</li>
<li>Shotaro Ichikawa, Yuki Onishi, Daigo Hayashi, Akiyuki Ebi, Isamu Endo, Aoi Suzuki, Anri Niwano, Kazuyuki Fujita, Kazuki Takashima, Yoshifumi Kitamura. Be Bait!: Hammock-based Interaction for Enjoyable Underwater Swimming in VR. Asian CHI Symposium: Emerging HCI Research Collection, May. 2019.</li>
<li>Yoshifumi Kitamura, Kazuki Takashima, Kazuyuki Fujita. Designing Dynamic Aware Interiors. Proc. of the 24th ACM Symposium on Virtual Reality Software and Technology (VRST &#39;18), pp. 77:1-77:2, Nov. 2018.</li>
<li>Xin Huang, Kazuki Takashima, Kazuyuki Fujita, Yoshifumi Kitamura. Dynamic, Flexible and Multi-dimensional Visualization of Digital Photos and their Metadata. Proc. of the 2018 ACM International Conference on Interactive Surfaces and Spaces (ISS &#39;18), pp.405-408, Nov. 2018.</li>
<li>Yohei Kojima, Kazuma Aoyama, Yuichi Itoh, Kazuyuki Fujita, Taku Fujimoto, and Kosuke Nakajima. Polka dot: the garden of water spirits. ACM SIGGRAPH 2013 Posters, Article No. 47, Jul. 2013.</li>
<li>Kosuke Nakajima, Yuichi Itoh, Yusuke Hayashi, Kazuaki Ikeda, Kazuyuki Fujita, Takao Onoye. Emoballoon, Proc. of The 10th Asia Pacific Conference on Computer Human Interaction (APCHI2012), Vol. 2, pp. 681-682, Aug. 2012. <em>Best Poster / Best Demo Award</em></li>
<li>Sho Tsugawa, Yukiko Mogi, Yusuke Kikuchi, Fumio Kishino, Kazuyuki Fujita, Yuichi Itoh, Hiroyuki Ohsaki. On estimating depressive tendencies of Twitter users utilizing their tweet data. Proc. of The 2nd International Workshop on Ambient Information Technologies (AMBIT &#39;13), pp.29-32, Mar. 2013.</li>
<li>Kosuke Nakajima, Yuichi Itoh, Yusuke Hayashi, Kazuaki Ikeda, Kazuyuki Fujita, and Takao Onoye. Emoballoon: a Balloon-shaped Interface Recognizing Social Touch Interactions. Proc. of The 2nd International Workshop on Ambient Information Technologies (AMBIT &#39;13), pp.13-16, Mar. 2013.</li>
<li>Yuichi Fujii, Fumio Kishino, Kazuyuki Fujita, Yuichi Itoh. U-brella: A portable umbrella-shaped device for vibrationizing information. Proc. of The 2nd International Workshop on Ambient Information Technologies (AMBIT &#39;13), pp.9-12, Mar. 2013.</li>
<li>Kazuyuki Fujita, Yuichi Itoh, Kazuki Takashima, Kosuke Nakajima, Yusuke Hayashi, and Fumio Kishino. Ambient Party Room: A Room-shaped System Enhancing Communication for Parties or Gatherings. Proc. of The 2nd International Workshop on Ambient Information Technologies (AMBIT &#39;13), pp.1-4, Mar. 2013.</li>
<li>Kazuki Takashima, Kazuyuki Fujita, Yuichi Itoh, Yoshifumi Kitamura. Elastic Scroll for Multi-focus Interactions, Adjunct Proc. of the 25th Annual ACM Symposium on User Interface Software and Technology (UIST &#39;12), pp. 19-20, Oct. 2012.</li>
<li>Kazuyuki Fujita, Yuichi Itoh, Hiroyuki Ohsaki, Naoaki Ono, Keiichiro Kagawa, Kazuki Takashima, Sho Tsugawa, Kosuke Nakajima, Yusuke Hayashi, Fumio Kishino. Ambient Suite: Room-shaped Information Environment for Interpersonal Communication, Proc. of The 1st International Workshop on Ambient Information Technologies (AMBIT &#39;12), pp. 18-21, Mar. 2012.</li>
<li>Kosuke Nakajima, Yuichi Itoh, Takayuki Tsukitani, Kazuyuki Fujita, Kazuki Takashima, Yoshifumi Kitamura, Fumio Kishino. FuSA2 Touch Display: Furry and Scalable Multi-touch Display, Proc. of The 1st International Workshop on Ambient Information Technologies (AMBIT &#39;12), pp. 35-36, Mar. 2012.</li>
<li>Yusuke Hayashi, Yuichi Itoh, Kazuki Takashima, Kazuyuki Fujita, Kosuke Nakajima, Ikuo Daibo, Takao Onoye. Cup-le: A Cup-Shaped Device for Conversational Experiment, Proc. of The 1st International Workshop on Ambient Information Technologies (AMBIT &#39;12), pp. 36-37, Mar. 2012.</li>
<li>Hiroyuki Kidokoro, Kazuyuki Fujita, Masanori Owaki, Khoa Doba, Christopher Chung, Yuichi Itoh. Paranga: A Book-shaped Device with Tactile Feedback, The 4th ACM SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia (SIGGRAPH Asia 2011) Emerging Technologies, Dec. 2011.</li>
<li>Ai Yoshida, Yuichi Itoh, Kazuyuki Fujita, Maya Ozaki, Kikukawa Tetsuya, Ryo Fukazawa, Yoshifumi Kitamura, Fumio Kishino. Funbrella: Making Rain Fun, ACM SIGGRAPH 2009 Emerging Technologies, No. 10, Aug. 2009.</li>

</ol>
<ul>
<li class="category">Reviewed Domestic Conference Papers</li>

</ul>
<ol>
<li>天間遼太郎，高嶋和毅，末田航，藤田和之，北村喜文．空間連動する2つのカメラ視点を用いたドローン操縦インタフェースの拡張．インタラクション2019論文集，pp. 102-111, 2019年3月．</li>
<li>工藤義礎，アンソニー タン，藤田和之，遠藤勇，高嶋和毅，ソール グリーンバーグ，北村喜文．近接学に基づくHMD利用者・非利用者の間の段階的なアウェアネスの向上．インタラクション2019論文集，pp. 48-57, 2019年3月．</li>
<li>中島康祐, 伊藤雄一, 林勇介, 池田和章, 藤田和之, 尾上孝雄. Emoballoon: ソーシャルタッチインタラクションのための風船型インタフェース. インタラクション2013論文集, pp. 95-102, 2013年3月．</li>
<li>大脇正憲，藤田和之，高嶋和毅，築谷喬之，伊藤雄一，北村喜文，岸野文郎．撓みのメタファを用いたビューポート制御インタフェース，インタラクション2011論文集, pp. 115-122, 2011年3月．</li>
<li>藤田和之，高嶋和毅，築谷喬之，朝日元生，北村喜文，岸野文郎．複数のカメラ操作を連動させる地図ナビゲーション手法の提案，インタラクション2009 論文集, pp. 97-104, 2009年3月．</li>

</ol>
<ul>
<li class="category">Non-reviewed Domestic Conference Papers</li>

</ul>
<ol>
<li>井上理哲人，天間遼太郎，藤田和之，高嶋和毅，北村喜文．ドローンとARを用いて交差点の死角を可視化するユーザインタフェース．電子情報通信学会総合大会論文集，pp. ISS-SP-078. 2019年3月．</li>
<li>Mengting Huang，藤田和之，高嶋和毅，真鍋宏幸，北村喜文．タッチスクリーン上に重ねた透明シートを利用した位置と速度制御の併用が可能なユーザインタフェース．インタラクション2019論文集，pp. 276-278, 2019年3月．<em>インタラクティブ発表賞．</em></li>
<li>藤田和之，西川政行，小笠原豊，白鳥毅，大橋一広，会議支援のための情報表出空間の構築，第31回人工知能学会全国大会，2P1-4，2017年5月．</li>
<li>津川翔，茂木佑希子，菊地佑介，岸野文郎，藤田和之，伊藤雄一，大崎博之，Twitter におけるユーザの活動履歴を利用したうつ傾向の推定に関する一検討，第 33 回インターネット技術第 163 委員会研究会, 2013年5月.</li>
<li>津川翔，茂木佑希子，菊地佑介，岸野文郎，藤田和之，伊藤雄一，大崎博之，Twitter 解析によるうつ傾向推定に関する一検討，電子情報通信学会総合大会講演論文集 (A-14-6), p.187, 2013年3月．</li>
<li>脇田昌紀，岸野文郎，藤田和之，伊藤雄一．SenseChairを用いた同調傾向の計測，電子情報通信学会総合大会講演論文集 (A-14-5), p.186, 2013年3月．</li>
<li>津川翔，茂木佑希子，菊地佑介，岸野文郎，藤田和之，伊藤雄一，大崎博之，大規模ツイートデータを利用したうつ傾向の推定に関する検討，電子情報通信学会技術研究報告 (HCS2012-89), pp.61-66, 2013年2月．</li>
<li>藤田和之，伊藤雄一，高嶋和毅，中島康祐，林勇介，岸野文郎．Ambient Party Room: パーティ場面における部屋型会話支援システムの構築，第91回ヒューマンインタフェース学会研究報告集，Vol. 14, No. 8, pp. 7-10, 2012年9月．</li>
<li>藤田和之，城所宏行，伊藤雄一．アナログパラパラデジタルマンガ，日本バーチャルリアリティ学会第17回大会 オーガナイズドセッション, 2012年9月．</li>
<li>藤井佑一，岸野文郎，藤田和之，中島康祐，伊藤雄一，菊地日出男．U-brella: 降り注ぐ情報を可振化するポータブル傘型インタフェース，日本バーチャルリアリティ学会第17回大会論文集，pp. 652-655, 2012年9月．</li>
<li>高嶋和毅，藤田和之，横山ひとみ，伊藤雄一，北村喜文．6人会話における非言語情報と場の活性度に関する検討，電子情報通信学会技術研究報告，Vol. 112, No. 176 pp. 49-54, 2012年8月．</li>
<li>遠藤隆介，伊藤雄一，中島康祐，藤田和之，岸野文郎．マルチタッチディスプレイを用いたプランニングができるデジタルサイネージシステムの提案，ヒューマンインタフェース学会研究報告集, Vol. 14, No. 8, 2012年6月．</li>
<li>児島陽平，伊藤雄一，藤田和之，中島康祐，尾上孝雄．空間内の複数人員配置のための指示位置提示手法に関する検討，ヒューマンインタフェース学会研究報告集, Vol. 14, No. 8, 2012年6月．</li>
<li>竹中拓也，岸野文郎，藤田和之，中島康祐，伊藤雄一．二者間の着座状態と会話の活性度の関係に関する検討，電子情報通信学会総合大会論文集, pp. A-14-2, 2012年3月．</li>
<li>新宅彩加，岸野文郎，石原のぞみ，藤田和之，伊藤雄一．書籍固有の情報を用いた書籍の明るさ判定，電子情報通信学会総合大会論文集, pp. A-16-19, 2012年3月．</li>
<li>林勇介，伊藤雄一，中島康祐，藤田和之，高嶋和毅，大坊郁夫，尾上孝雄．カップ型デバイス Cup-le を用いた会話実験支援手法，ヒューマンインタフェースシンポジウム2011論文集, pp. 405-408, 2011年9月．</li>
<li>藤田和之，高嶋和毅，伊藤雄一，大崎博之，小野直亮，香川景一郎，津川翔，中島康祐，林勇介，岸野文郎．Ambient Suite: 部屋型情報空間を用いた対人コミュニケーション支援，ヒューマンインタフェースシンポジウム2011論文集, pp. 395-400, 2011年9月．</li>
<li>大脇正憲，藤田和之，高嶋和毅，伊藤雄一，北村喜文．マルチタッチ入力環境における撓みスクロール・ズーム手法，ヒューマンインタフェースシンポジウム2011論文集, pp. 429-434, 2011年9月．<em>学術奨励賞．</em></li>
<li>藤井佑一，岸野文郎，藤田和之，伊藤雄一．振動ディスプレイを用いた情報可振化インタフェースの一検討，日本バーチャルリアリティ学会第16回大会論文集, pp. 14C-1, 2011年9月．</li>
<li>前田奈穂，大坊郁夫，藤田和之．関係開始スキルがパーティ場面におけるコミュニケーション行動に及ぼす影響，電子情報通信学会技術研究報告, Vol. 111, No. 190, pp. 5-10, 2011年8月．</li>
<li>城所宏行，藤田和之，大脇正憲，Khoa Doba，Christopher Chung，伊藤雄一．パランガ：ページをめくる触感を再現する本型デバイス，インタラクション2011 論文集, pp. 609-612, 2011年3月．</li>
<li>中島康祐，伊藤雄一，築谷喬之，藤田和之，高嶋和毅，岸野文郎．FuSA2 Touch Display: 大画面毛状マルチタッチディスプレイ，インタラクション2011論文集, pp. 547-550, 2011年3月．</li>
<li>藤井佑一，藤川翔平，岸野文郎，藤田和之，伊藤雄一．情報可振化インタフェース実現のための一検討，電子情報通信学会総合大会論文集, pp. A-15-20, 2011年3月．</li>
<li>藤田和之，高嶋和毅，築谷喬之，伊藤雄一，北村喜文，岸野文郎．地図ナビゲーションにおけるバーチャルカメラのパン・ズーム・チルトの連動に関する検討，日本バーチャルリアリティ学会第15回大会論文集, pp. 3B1-2, 2010年9月．</li>
<li>吉田愛，伊藤雄一，尾崎麻耶，菊川哲也，深澤遼，藤田和之，高嶋和毅，北村喜文，岸野文郎．アソブレラ：雨の振動を記録・再生する傘型デバイス，インタラクティブ東京2009シンポジウム，2009年10月．</li>
<li>藤田和之，伊藤雄一，吉田愛，尾崎麻耶，菊川哲也，深澤遼，高嶋和毅，北村喜文，岸野文郎．アソブレラ：雨と遊ぶ，エンタテインメントコンピューティング2009 (EC2009) 論文集, pp. 73-74, 2009年9月．</li>
<li>藤田和之，高嶋和毅，築谷喬之，北村喜文，岸野文郎．パン操作にズームとチルトを連動させる地図ナビゲーション，画像の認識・理解シンポジウム（MIRU2009）論文集, pp. 1875-1876, 2009年7月．</li>
<li>吉田愛，伊藤雄一，尾崎麻耶，菊川哲也，深澤遼，藤田和之，北村喜文，岸野文郎．アソブレラ：傘軸の振動を記録・再生するシステムの検討，電子情報通信学会技術研究報告, Vol. 109, No. 75, pp. 65-68, 2009年6月．</li>

</ol>
<ul>
<li class="category">Patents</li>

</ul>
<ol>
<li>コミュニケーション支援システム，特願2016-093239，2016年5月6日，特開2017-201479，2017年11月9日．</li>
<li>表示装置およびプログラム，特願2011-051234，2011年3月9日．
他
 出願 6件</li>

</ol>
<ul>
<li class="category">Awards</li>

</ul>
<ol>
<li>Yoshitaka Ishihara, Shori Ueda, Yuichi Itoh, Kazuyuki Fujita. PlanT: A Plant-based Ambient Display Visualizing Gradually Accumulated Information. Asian CHI Symposium: Emerging HCI Research Collection, May. 2019. <em>Best Demo/Poster Awards (5 out of 52 presentations).</em></li>
<li>Mengting Huang，藤田和之，高嶋和毅，真鍋宏幸，北村喜文．タッチスクリーン上に重ねた透明シートを利用した位置と速度制御の併用が可能なユーザインタフェース．インタラクション2019論文集，pp. 276-278, 2019年3月．<em>インタラクティブ発表賞（214件中7件）．</em></li>
<li>Kosuke Nakajima, Yuichi Itoh, Yusuke Hayashi, Kazuaki Ikeda, Kazuyuki Fujita, Takao Onoye. Emoballoon. The 10th Asia Pacific Conference on Computer Human Interaction (APCHI2012), Aug. 2012. <em>Best Poster / Demonstration Award. </em></li>
<li>大脇正憲，藤田和之，高嶋和毅，伊藤雄一，北村喜文．マルチタッチ入力環境における撓みスクロール・ズーム手法，ヒューマンインタフェースシンポジウム2011論文集, pp. 429-434, 2011年9月．第12回 ヒューマンインタフェース学会 <em>学術奨励賞</em> (2011年度)，</li>
<li>第18回 国際学生対抗バーチャルリアリティコンテスト (IVRC2010) <em>明和電機社長賞</em>，作品名：パランガ，2010年8月．</li>
<li>第16回 国際学生対抗バーチャルリアリティコンテスト (IVRC2008) 東京予選大会 ハンズオン部門 <em>優勝</em>．作品名：アソブレラ，2008年9月．</li>
<li>第16回 国際学生対抗バーチャルリアリティコンテスト (IVRC2008) 岐阜本戦大会 <em>審査員特別賞，各務原市民賞</em>．作品名：アソブレラ，2008年11月．</li>

</ol>
<ul>
<li class="category">Invited Talks</li>

</ul>
<ol>
<li>働き方変革と未来のワークプレイス，東北大学，第4回 共同プロジェクト研究会「人と空間と情報技術」，2018年3月12日．</li>
<li>山田茂雄，藤田和之．アイデアが生まれる空間に住まう「もうひとりの参加者」，東京大学，日本ロボット学会セミナー 第107回 インタラクションにより人や環境に適応するロボット・ＡＩの行動戦略，2017年8月8日．</li>
<li>会議支援のための情報表出空間，東北大学，第3回 共同プロジェクト研究会「人と空間と情報技術」，2017年3月7日．</li>
<li>Office Vision 2020 ～近未来の社会情勢予測から逆引きするオフィス像～，東北大学，第2回 共同プロジェクト研究会「人と空間と情報技術」，2016年2月23日．</li>
<li>協創空間 ～トランスボーダーなクリエイティブ・プラットフォームへの仕掛け～，スルガ銀行d-laboミッドタウン セミナー，2015年8月27日．</li>
<li>イトーキとICT，東北大学，第1回 共同プロジェクト研究会「人と空間と情報技術」，2015年3月14日．</li>

</ol>
 						</div>
					</div>
				</div>
			</div>
			<!-- /.container -->
		</section>

		<p id="back-top">
			<a href="#top"><i class="fa fa-angle-up"></i></a>
		</p>
		<footer>
			<div class="container text-center">
				<p>Designed by <a href="http://moozthemes.com"><span>MOOZ</span>Themes.com</a></p>
			</div>
		</footer>

		<!-- Modal for portfolio item 1 -->
		<div class="modal fade" id="Modal-1" tabindex="-1" role="dialog" aria-labelledby="Modal-label-1">
			<div class="modal-dialog" role="document">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
						<h4 class="modal-title" id="Modal-label-1">Dean & Letter</h4>
					</div>
					<div class="modal-body">
						<img src="images/demo/portfolio-1.jpg" alt="img01" class="img-responsive" />
						<div class="modal-works"><span>Branding</span><span>Web Design</span></div>
						<p>Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe</p>
					</div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
					</div>
				</div>
			</div>
		</div>

		<!-- Modal for portfolio item 2 -->
		<div class="modal fade" id="Modal-2" tabindex="-1" role="dialog" aria-labelledby="Modal-label-2">
			<div class="modal-dialog" role="document">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
						<h4 class="modal-title" id="Modal-label-2">Startup Framework</h4>
					</div>
					<div class="modal-body">
						<img src="images/demo/portfolio-2.jpg" alt="img01" class="img-responsive" />
						<div class="modal-works"><span>Branding</span><span>Web Design</span></div>
						<p>Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe</p>
					</div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
					</div>
				</div>
			</div>
		</div>

		<!-- Modal for portfolio item 3 -->
		<div class="modal fade" id="Modal-3" tabindex="-1" role="dialog" aria-labelledby="Modal-label-3">
			<div class="modal-dialog" role="document">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
						<h4 class="modal-title" id="Modal-label-3">Lamp & Velvet</h4>
					</div>
					<div class="modal-body">
						<img src="images/demo/portfolio-3.jpg" alt="img01" class="img-responsive" />
						<div class="modal-works"><span>Branding</span><span>Web Design</span></div>
						<p>Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe</p>
					</div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
					</div>
				</div>
			</div>
		</div>

		<!-- Modal for portfolio item 4 -->
		<div class="modal fade" id="Modal-4" tabindex="-1" role="dialog" aria-labelledby="Modal-label-4">
			<div class="modal-dialog" role="document">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
						<h4 class="modal-title" id="Modal-label-4">Smart Name</h4>
					</div>
					<div class="modal-body">
						<img src="images/demo/portfolio-4.jpg" alt="img01" class="img-responsive" />
						<div class="modal-works"><span>Branding</span><span>Web Design</span></div>
						<p>Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe</p>
					</div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
					</div>
				</div>
			</div>
		</div>

		<!-- Modal for portfolio item 5 -->
		<div class="modal fade" id="Modal-5" tabindex="-1" role="dialog" aria-labelledby="Modal-label-5">
			<div class="modal-dialog" role="document">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
						<h4 class="modal-title" id="Modal-label-5">Fast People</h4>
					</div>
					<div class="modal-body">
						<img src="images/demo/portfolio-5.jpg" alt="img01" class="img-responsive" />
						<div class="modal-works"><span>Branding</span><span>Web Design</span></div>
						<p>Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe</p>
					</div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
					</div>
				</div>
			</div>
		</div>

		<!-- Bootstrap core JavaScript
			================================================== -->
		<!-- Placed at the end of the document so the pages load faster -->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/SmoothScroll.js"></script>
		<script src="js/theme-scripts.js"></script>
	</body>
</html>
